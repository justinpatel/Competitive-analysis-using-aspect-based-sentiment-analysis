{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be116d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "#Reading all the reviews and merging it\n",
    "df1 = pd.read_excel('/Users/ksharath/Downloads/aws.xlsx',engine='openpyxl')\n",
    "df2 = pd.read_excel('/Users/ksharath/Downloads/gcloud_text.xlsx',engine='openpyxl')\n",
    "df3 = pd.read_csv('/Users/ksharath/Downloads/azure_cleaned_reviews.csv')\n",
    "df3.columns = df1.columns\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "df['text'] = df [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b67671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a8bb3",
   "metadata": {},
   "source": [
    "***Pre processing for reviews text***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "038c9f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aws, love, lambda]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AWS we love Lambda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[multiple, locations, databases, services, ava...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple locations and databases . Some servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[aws, great, cms, iam, easy, use, add, users, ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AWS has a great CMS IAM were easy to use to ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, factor, authentication, sometime, would, r...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2 factor authentication sometime would rest mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[developer, certifications]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Had more Developer with certifications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  Unnamed: 0  \\\n",
       "0                                [aws, love, lambda]         0.0   \n",
       "1  [multiple, locations, databases, services, ava...         1.0   \n",
       "2  [aws, great, cms, iam, easy, use, add, users, ...         3.0   \n",
       "3  [2, factor, authentication, sometime, would, r...         5.0   \n",
       "4                        [developer, certifications]         6.0   \n",
       "\n",
       "                                                text  \n",
       "0                                 AWS we love Lambda  \n",
       "1  Multiple locations and databases . Some servic...  \n",
       "2  AWS has a great CMS IAM were easy to use to ad...  \n",
       "3  2 factor authentication sometime would rest mu...  \n",
       "4             Had more Developer with certifications  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#preprocess\n",
    "def pre_process(x):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #stop_words= set(stop_words.update(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]))\n",
    "    #unwanted = ['would','should','']\n",
    "    #word_tokens = word_tokenize(example_sent)\n",
    "    filtered_sentence = [w for w in x if not w.lower() in stop_words]\n",
    "    return filtered_sentence\n",
    "\n",
    "#Tokenize\n",
    "df[0] = df[0].apply(lambda x: re.sub(r\"[^a-zA-Z0-9]\", \" \", x.lower()).split())\n",
    "df[0] = df[0].apply(lambda x: pre_process(x))\n",
    "                    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc486706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare a word set\n",
    "new_list = df[0].tolist()\n",
    "wordset=[]\n",
    "for i in new_list:\n",
    "    wordset = np.union1d(wordset,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef1502",
   "metadata": {},
   "source": [
    "***Function for TF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f94b1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateTF(wordset,bow):\n",
    "  termfreq_diz = dict.fromkeys(wordset,0)\n",
    "  counter1 =  dict(collections.Counter(bow))\n",
    "  for w in bow:\n",
    "    termfreq_diz[w]=counter1[w]/len(bow)\n",
    "  return termfreq_diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7376c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of Topic frequenxy TF\n",
    "doc_dic ={}\n",
    "for doc in df[0].to_list():\n",
    "    doc_dic[tuple(doc)] = calculateTF(wordset,doc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c22d74",
   "metadata": {},
   "source": [
    "***Function for IDF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "474550b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IDF(wordset,bow):\n",
    "    d_bow = {'bow_{}'.format(i):list(set(b)) for i,b in enumerate(bow)}\n",
    "    N=len(d_bow.keys())\n",
    "    l_bow = []\n",
    "    for b in d_bow.values():\n",
    "      l_bow+=b\n",
    "    counter = dict(collections.Counter(l_bow))\n",
    "    idf_diz=dict.fromkeys(wordset,0)\n",
    "    for w in wordset:\n",
    "      idf_diz[w] = np.log((1+N)/(1+counter[w]))+1\n",
    "    return idf_diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d4705f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_diz = calculate_IDF(wordset,df[0].tolist())\n",
    "\n",
    "df_idf = pd.DataFrame([idf_diz])\n",
    "#df_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06b59e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TF_IDF(wordset,tf_diz,idf_diz):\n",
    "    tf_idf_diz = dict.fromkeys(wordset,0)\n",
    "    for w in wordset:\n",
    "       tf_idf_diz[w]=tf_diz[w]*idf_diz[w]\n",
    "    tdidf_values = list(tf_idf_diz.values())\n",
    "    l2_norm = LA.norm(tdidf_values)   \n",
    "    tf_idf_norm = {w:tf_idf_diz[w]/l2_norm for w in wordset}\n",
    "    return tf_idf_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70847f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_doc_dic= {}\n",
    "for doc in df[0].to_list():\n",
    "    \n",
    "    tfidf_doc_dic[tuple(doc)] = calculate_TF_IDF(wordset,doc_dic[tuple(doc)],idf_diz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f6ef4",
   "metadata": {},
   "source": [
    "**Let's also create Sentiment scoring here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7f1e256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>calculated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aws, love, lambda]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AWS we love Lambda</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[multiple, locations, databases, services, ava...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple locations and databases . Some servic...</td>\n",
       "      <td>0.384091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[aws, great, cms, iam, easy, use, add, users, ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AWS has a great CMS IAM were easy to use to ad...</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, factor, authentication, sometime, would, r...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2 factor authentication sometime would rest mu...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[developer, certifications]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Had more Developer with certifications</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  Unnamed: 0  \\\n",
       "0                                [aws, love, lambda]         0.0   \n",
       "1  [multiple, locations, databases, services, ava...         1.0   \n",
       "2  [aws, great, cms, iam, easy, use, add, users, ...         3.0   \n",
       "3  [2, factor, authentication, sometime, would, r...         5.0   \n",
       "4                        [developer, certifications]         6.0   \n",
       "\n",
       "                                                text  calculated  \n",
       "0                                 AWS we love Lambda    0.500000  \n",
       "1  Multiple locations and databases . Some servic...    0.384091  \n",
       "2  AWS has a great CMS IAM were easy to use to ad...    0.555556  \n",
       "3  2 factor authentication sometime would rest mu...    0.000000  \n",
       "4             Had more Developer with certifications    0.500000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['calculated'] = df['text'].apply(lambda x: (TextBlob(x).sentiment.polarity))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4f7de5",
   "metadata": {},
   "source": [
    "**Tagging the topics from TF-IDF with a final score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3e22a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_l =[]\n",
    "for doc in df[0].to_list():\n",
    "    json_l.append(tfidf_doc_dic[tuple(doc)])\n",
    "final_df = pd.DataFrame(json_l)\n",
    "\n",
    "final_df_stat = final_df.mean()\n",
    "output = pd.DataFrame(final_df_stat)\n",
    "#Here we can get top 50 or top 100 topics\n",
    "\n",
    "#output = pd.DataFrame(final_df_stat).nlargest(50, 0)\n",
    "final_list =[]\n",
    "for i in output.iterrows():\n",
    "    #print(\"Iterating for topic: %s\"%i[0])\n",
    "    sent_score = 0\n",
    "    for j in df.iterrows():\n",
    "        if i[0] in j[1]['text'].lower():\n",
    "            sent_score = sent_score + j[1]['calculated']\n",
    "    #print(\"Original TF-IDF score\")\n",
    "    #print(i[1][0])\n",
    "    #print(\"TF-IDF with sentiment score\")\n",
    "    #print(i[1][0]*sent_score)\n",
    "    #print(\"\\n\")\n",
    "    final_list.append([ i[0], i[1][0], i[1][0]*sent_score])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49a6e986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 196.0186710357666 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model_output = pd.DataFrame(final_list)\n",
    "model_output.columns = [\"Topic_name\", \"TFIDF\", \"TFIDF_with_sentiment\"]\n",
    "#Let's write the output to the output file now\n",
    "model_output.to_csv(\"~/Desktop/output_TFIDF.csv\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d9048",
   "metadata": {},
   "source": [
    "**Sentiment Analyzer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "307a6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330e146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4722568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d813fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee451dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
